{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b3e372-90c5-421f-bdc4-7e0cad8aa74b",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cf481a-7603-4022-9fac-b1298e65ebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\weigfan\\AppData\\Local\\anaconda3\\envs\\narrativezoo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests \n",
    "import tiktoken\n",
    "import ray\n",
    "import numpy as np\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "# In order for ray to work, make sure you uninstall pydantic and reinstall this: pip install \"pydantic<2\"\n",
    "from openai import OpenAI\n",
    "from class_model.model import Model\n",
    "from utils.system import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c2f14-7dd5-4e85-b3e5-f49c5dcde724",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ce752-ef28-4fa6-99c5-d4e08a2c985f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collect = []\n",
    "for i in range(1, 6):\n",
    "    collect.append(pd.read_parquet(get_format_data() / 'art' / f'wsj_art_{i}.parquet.brotli'))\n",
    "wsj_multiple = pd.concat(collect, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2567d9-9a23-46b2-99c3-a560b22da3e6",
   "metadata": {},
   "source": [
    "### Parallelized: Get number of tokens (per article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52d40c-4445-4438-b828-ac40f7baca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def get_token_count(article_text, encoding_param):\n",
    "    encoding = tiktoken.get_encoding(encoding_param)\n",
    "    token_count = len(encoding.encode(article_text))\n",
    "    return token_count\n",
    "\n",
    "def process_tokens_in_batches(df, column_name, encoding_param, batch_size):\n",
    "    num_batches = np.ceil(len(df) / batch_size)\n",
    "    all_token_counts = []\n",
    "    print(f\"Number of batches: {int(num_batches)}\")\n",
    "\n",
    "    for i in range(int(num_batches)):\n",
    "        print(f\"Processing batch: {i + 1}/{int(num_batches)}\")\n",
    "        start_index = i * batch_size\n",
    "        end_index = start_index + batch_size\n",
    "        batch = df[column_name][start_index:end_index]\n",
    "\n",
    "        # Start asynchronous tasks for the batch\n",
    "        futures = [get_token_count.remote(text, encoding_param) for text in batch]\n",
    "        token_counts = ray.get(futures)\n",
    "        all_token_counts.extend(token_counts)\n",
    "\n",
    "    # Assign the token counts back to the DataFrame\n",
    "    df['n_tokens'] = all_token_counts\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7939396-bc21-4cf6-ba14-2c71fbb9c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_encoding = \"cl100k_base\" \n",
    "max_tokens = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961127bd-50dc-4ac8-9f09-fff4b63c60b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "\n",
    "# Process articles in batches\n",
    "ray.init(num_cpus=16, ignore_reinit_error=True)\n",
    "start_time = time.time()\n",
    "wsj_multiple = process_tokens_in_batches(wsj_multiple, 'body_txt', embedding_encoding, batch_size)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Total time to get all tokens: {round(elapsed_time)} seconds\")\n",
    "\n",
    "# Shutdown Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2ee27-74fa-4d94-9dd8-094a4fcdb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "print(f\"Length before: {len(wsj_multiple)}\")\n",
    "wsj_multiple = wsj_multiple[wsj_multiple.n_tokens <= max_tokens]\n",
    "print(f\"Length after: {len(wsj_multiple)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1f3b0-5c7c-4a24-93f2-d5e110dc269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data\n",
    "chunks = np.array_split(wsj_multiple, 8)\n",
    "for i, df in enumerate(chunks, 1):\n",
    "    print(i)\n",
    "    df.to_parquet(get_format_data() / 'token' / f'wsj_tokens_{i}.parquet.brotli', compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4170c5d-0d02-408d-87b3-fc10660f9083",
   "metadata": {},
   "source": [
    "### Parallelized: Get embeddings (per article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9949db1-5189-47da-9420-e770bbf8dbc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in token dataset\n",
    "collect = []\n",
    "for i in range(1, 9):\n",
    "    collect.append(pd.read_parquet(get_format_data() / 'token' / f'wsj_tokens_{i}.parquet.brotli'))\n",
    "wsj_multiple = pd.concat(collect, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3d9ba2-cae2-47b5-b7d0-9bc17941d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj_multiple_token = wsj_multiple.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5584ebe9-bd33-4ea1-9f04-ec0172f16c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def get_embedding_article(article_text, model):\n",
    "    api_key = json.load(open(get_config() / 'api.json'))['openai_api_key']\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    embedding = client.embeddings.create(input=[article_text.replace(\"\\n\", \" \")], model=model).data[0].embedding\n",
    "    return embedding\n",
    "\n",
    "def process_articles_in_batches(df, column_name, model, batch_size, delay_per_batch):\n",
    "    num_batches = np.ceil(len(df) / batch_size)\n",
    "    \n",
    "    with tqdm.tqdm(total=int(num_batches), desc=\"Processing batches\") as pbar:\n",
    "        for i in range(int(num_batches)):\n",
    "            # Check if the batch has already been processed\n",
    "            save_path = get_format_data() / 'openai' / f'wsj_emb_textemb3small_{i}.parquet.brotli'\n",
    "            if save_path.exists():\n",
    "                tqdm.write(f\"Skipping batch {i + 1}/{int(num_batches)} (already processed)\")\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            # Get batch\n",
    "            start_index = i * batch_size\n",
    "            end_index = min(start_index + batch_size, len(df))\n",
    "            batch = df[column_name][start_index:end_index]\n",
    "            \n",
    "            # Start asynchronous tasks for the batch\n",
    "            futures = [get_embedding_article.remote(text, model) for text in batch]\n",
    "            embeddings = ray.get(futures)\n",
    "\n",
    "            # Save Batch\n",
    "            tqdm.write(f\"Saving progress to {save_path}\")\n",
    "            all_indices = df.index[start_index:end_index].tolist()\n",
    "            temp_df = pd.DataFrame({'ada_embedding': embeddings}, index=all_indices)\n",
    "            temp_df.to_parquet(save_path, compression='brotli')             \n",
    "            tqdm.write(\"Progress saved\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Delay between batches if specified\n",
    "            if delay_per_batch > 0:\n",
    "                time.sleep(delay_per_batch)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2689d29c-f265-441b-913d-a07196020cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 14:56:12,216\tINFO worker.py:1673 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|                                                                                                                                                                                                                        | 0/832 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: 1/832\n",
      "Saving progress to C:\\Jonathan\\QuantResearch\\AlgoTradingModels\\fenui\\data\\format\\openai\\wsj_emb_textemb3small_0.parquet.brotli...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|▏                                                                                                                                                                                                           | 1/832 [02:47<38:33:56, 167.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved\n",
      "Processing batch: 2/832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|▏                                                                                                                                                                                                           | 1/832 [03:04<42:36:54, 184.61s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "model_name = 'text-embedding-3-small'\n",
    "batch_size = 1000\n",
    "delay_per_batch = 60\n",
    "\n",
    "# Process articles in batches\n",
    "ray.init(num_cpus=16, ignore_reinit_error=True)\n",
    "\n",
    "start_time = time.time()\n",
    "process_articles_in_batches(wsj_multiple_token, 'body_txt', model_name, batch_size, delay_per_batch)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Total time to get all embeddings: {round(elapsed_time)} seconds\")\n",
    "\n",
    "# Shutdown Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed4fb9-507c-4419-a001-3b2b458556c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narrativezoo",
   "language": "python",
   "name": "narrativezoo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
