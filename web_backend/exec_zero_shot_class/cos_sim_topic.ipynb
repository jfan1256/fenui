{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa4e0b3-bc03-423c-bbe2-103be79cdf33",
   "metadata": {},
   "source": [
    "#### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21cd494f-b748-4e68-870c-1b4b75979136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\weigfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests \n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "import openai\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from utils.system import *\n",
    "from class_data.data import Data\n",
    "from class_model.model import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e614f8-6d2f-4fbb-bb87-e3b051066e6d",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234f5282-7ff5-4781-b87f-7fbfaad99ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830899, 4)\n"
     ]
    }
   ],
   "source": [
    "# Multiple Articles per Day Data\n",
    "wsj_multiple = Data(folder_path=get_format_data() / 'token', file_pattern='wsj_tokens_*')\n",
    "wsj_multiple = wsj_multiple.concat_files()\n",
    "# Set limit to the exact same value used in embedding_similarity.ipynb to align indexes\n",
    "limit = 30\n",
    "count = wsj_multiple.groupby(wsj_multiple.index)['accession_number'].count()\n",
    "valid_dates_mask = count >= limit\n",
    "wsj_multiple = wsj_multiple[wsj_multiple.index.isin(count[valid_dates_mask].index)]\n",
    "print(wsj_multiple.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bea4e0-1538-4b20-8a25-4cf05acada27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830899, 1)\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = pd.read_parquet(get_format_data() / 'cosine_sim' / 'wsj_cosine_sim.parquet.brotli')\n",
    "print(cosine_sim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308cc01-5139-4a41-b1ea-8a7827675436",
   "metadata": {},
   "source": [
    "#### Retrieve Top N% Cosine Similarity Article Per Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da23def5-c4b6-4c16-97ee-672c7d04afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cosine_sim with matching article\n",
    "num_label = len(cosine_sim.columns)\n",
    "cosine_sim_label = [f'cosine_sim_{i}' for i in range(num_label)]\n",
    "cosine_sim_change = [f'relu_cosine_sim_{i}' for i in range(num_label)]\n",
    "combine = pd.concat([cosine_sim, wsj_multiple], axis=1)\n",
    "# Apply Relu Transformation to each column\n",
    "combine[cosine_sim_change] = np.maximum(0, cosine_sim[cosine_sim_label] - 0.75)\n",
    "# Aggregate across label columns\n",
    "combine['cosine_sim_mean'] = combine[cosine_sim_change].mean(axis=1).to_frame()\n",
    "combine.index.names = ['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3635532-9c1a-4454-90ce-8286d89fd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top N% of each group\n",
    "def top_n_per(group, N_percent):\n",
    "    n = int(len(group) * N_percent)\n",
    "    return group.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee5127a-42a1-426c-aea3-597941b22d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_percent = 0.10\n",
    "# Make Sure to Sort\n",
    "combine = combine.sort_values(['cosine_sim_mean'], ascending=False)\n",
    "top_n = combine.groupby('date').apply(top_n_per, N_percent).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357557a-be00-4a4b-93ea-c5a28f62e88d",
   "metadata": {},
   "source": [
    "#### Parallelized: ChatGPT Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d40d82d6-0a96-45f3-ba08-f005767140bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def summarize_article(article_text):\n",
    "    api_key = json.load(open(get_config() / 'api.json'))['openai_api_key']\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following article in two sentences:\\n\\n{article_text}\"}\n",
    "        ]\n",
    "    )\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    summary = summary.replace('\\xa0', ' ')\n",
    "    return summary\n",
    "\n",
    "def summarize_in_batches(df, new_column_name, column_name, batch_size):\n",
    "    num_batches = np.ceil(len(df) / batch_size)\n",
    "    all_summary = []\n",
    "    print(f\"Number of batches: {int(num_batches)}\")\n",
    "    for i in range(int(num_batches)):\n",
    "        print(f\"Processing batch: {i + 1}/{int(num_batches)}\")\n",
    "        start_index = i * batch_size\n",
    "        end_index = min(start_index + batch_size, len(df))\n",
    "        batch = df[column_name][start_index:end_index]\n",
    "        \n",
    "        # Start asynchronous tasks for the batch\n",
    "        futures = [summarize_article.remote(text) for text in batch]\n",
    "        embeddings = ray.get(futures)\n",
    "\n",
    "        # Update lists\n",
    "        all_summary.extend(embeddings)\n",
    "\n",
    "    df[new_column_name] = all_summary\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e90ce974-08d2-4206-b268-015135f1204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = top_n.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f3f5d8e-b60c-4f53-9902-ba650f346865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 16:19:50,267\tINFO worker.py:1673 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 1\n",
      "Processing batch: 1/1\n",
      "Total time to get all embeddings: 6 seconds\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 5\n",
    "new_col = 'gpt_summary'\n",
    "art_col = 'body_txt'\n",
    "\n",
    "# Process articles in batches\n",
    "ray.init(num_cpus=16, ignore_reinit_error=True)\n",
    "\n",
    "start_time = time.time()\n",
    "summary = summarize_in_batches(test, new_col, art_col, batch_size)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Total time to get all embeddings: {round(elapsed_time)} seconds\")\n",
    "\n",
    "# Shutdown Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b41d223-87b1-4f06-96ee-9f3c025fee01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CANTON Mass.  Ovation Technologies a closely held yearold computersoftware company which some observers think will be the next hot company in the booming industry said it raised 5.5 million from venture capitalists to develop and market its product. Computersoftware companies are currently appealing to venture capitalists because their role in the personalcomputer industry is booming and appears somewhat less risky than the computerhardware market which is undergoing a shakeout. Ovations financing is among the largest for software firms according to Stanley Pratt publisher of Venture Capital Journal. Ovation has yet to market its product an integrated software package that combines wordprocessing financial analysis and graphics in a single 795 program. However industry analysts who have seen it say it surpasses current products. I wasnt prepared to be impressed but I was said Esther Dyson president of Rosen Research Inc. a New York City firm that follows the personalcomputer industry. Ovations financing was led by Oak Investment Partners III of Westport Conn. and included a number of other venture capital firms and individuals. Edward Glassmeyer president of Oak Management Co. adviser to the partnership said It was a very hot deal. Oak Management has led financings for such companies as Seagate Technologies Inc. and Data Switch Corp. both of which are currently publicly held. Oak Investment Partners invested about onequarter of the amount Mr. Glassmeyer said. Other major investors included J.F. Shea  Co. of Walnut Calif. and Glenwood Management of Menlo Park Calif. he said. The investors acquired a minority stake in the company he added but he declined to disclose their percentage ownership. Interest in computersoftware companies has been high in recent months especially since the success of Lotus Development Corp. of Cambridge Mass. developer of a program called Lotus 123. Lotus started shipping its product last January and the company sold 2.6 million shares to the public in October at 18 each. Overall the market for computer software amounted to about 1.4 billion in 1983 with sales growing an estimated 40 annually. Most companies in the industry are closely held but more public offerings are expected during 1984. Ovations Ovation Software is an integrated program like Lotus 123 but is supposed to be easier to use since users need to remember only 30 English language commands to make it work. Integrated packages allow users to do wordprocessing financial analysis and graph creation using a single program rather than having to keep switching computer disks. Ovation like most software companies started out designing its product for International Business Machines Corp.s Personal Computer. However in November Tandy Corp. selected Ovation software as one of the programs it will sell in Radio Shack stores for its new Tandy 2000 personal computer. Ovation said it will have the program ready for both the IBM and Tandy products in early spring. Later it plans to design the software to run on other computers as well. Ovation was founded by Thomas J. Gregory formerly vice president for marketing of Saddlebrook Corp. Cambridge a closely held maker of computer software for minicomputer systems. Ovation raised 1.3 million in December 1982 through a private placement and has been developing its product since then. END'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['body_txt'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66a3ee46-ebdb-4a17-8faf-ffbd7e7150e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ovation Technologies, a privately-held computer software company focused on an integrated software package, has raised $5.5m\\xa0from venture capitalists to develop and market its product. Ovation's package, which includes word-processing, financial analysis, and graphics all in a single program, is set to surpass current products on the market by featuring an easy-to-use command system.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['gpt_summary'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b6102-8834-4b49-8b7f-54d7e2c995a6",
   "metadata": {},
   "source": [
    "#### BERT Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea360deb-4edd-4db6-b619-c1f8ee1a04b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Summaries\n",
    "docs = summary['gpt_summary'].tolist()\n",
    "\n",
    "# BERTopic\n",
    "# Note: Must install https://visualstudio.microsoft.com/visual-cpp-build-tools/ --> C++ Build Tool --> for hbdscan package within bertopic\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# Define linkage function for hierarchical topic modeling\n",
    "linkage_function = lambda x: sch.linkage(x, 'single', optimal_ordering=True)\n",
    "\n",
    "# Generate hierarchical topics\n",
    "hierarchical_topics = topic_model.hierarchical_topics(docs, linkage_function=linkage_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766f5b5-e4be-4de0-8a30-9fd670af755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Tree\n",
    "tree = topic_model.get_topic_tree(hierarchical_topics)\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narrativezoo",
   "language": "python",
   "name": "narrativezoo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
